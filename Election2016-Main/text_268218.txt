Fake news has spread across Facebook this election season like a bad cold, and the social media giant is finally putting the kibosh on the ability to unwittingly share false articles. Facebook announced this week it will make it easier for users to flag stories as fake news, and those stories will be send to third-party fact-checkers for review. The company said it will be working specifically with organizations that have signed Poynter's International Fact-Checking Network's code of principles, which currently includes 43 organizations. Organizations such as Politifact, the Washington Post' Fact Checker, the Associated Press, Snopes and a host of fact-checking media outlets internationally will receive the flagged posts. If the posts do not meet their standards of accuracy—for example, if a claim has no sourcing, or if it is based on another organization's report that lacks sourcing—Facebook will mark it as "fake" and will display a warning message when someone tries to share it. "We've focused our efforts on the worst of the worst," Facebook Vice President of Newsfeed Adam Mosseri said in a statement, "on the clear hoaxes spread by spammers for their own gain, and on engaging both our community and third party organizations." Some organizations in Poynter's International Fact-Checking Network, such as Politifact, exclusively publish reports related to the accuracy of statements made by politicians, important political figures and, recently, viral stories. Their Truth-O-Meter ranges from True to Pants on Fire, and their reporters write a detailed explanation of the ranking and their process in dissecting the statements. The key here is these organizations go into the work without specifically trying to disprove the statement. Their goal, instead, is to look at each part of the statement and evaluate whether the statement as a whole is truthful and an accurate representation of the situation described. Is there context missing? Is a complex problem being boiled down to a too-simple nugget? Or is someone flat-out lying? Fake news proliferated this year since some bloggers were able to get ad revenue from writing false and misleading articles that focused on sensational accusations. "It's important to us that the stories you see on Facebook are authentic and meaningful. We're excited about this progress, but we know there's more to be done. We're going to keep working on this problem for as long as it takes to get it right," Mosseri said. While Facebook's measures still leave plenty of room for human error and bias, they've finally made one step toward tackling a rampant problem. Get six of our favorite Motherboard stories every day by signing up for our newsletter.